<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Age Detection AI</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <style>
    body {
      margin: 0;
      font-family: 'Roboto', sans-serif;
      background: linear-gradient(135deg, #1a1a1a, #3d3d3d);
      color: #fff;
      display: flex;
      flex-direction: column;
      align-items: center;
      min-height: 100vh;
    }
    header {
      padding: 20px;
      text-align: center;
      font-size: 2rem;
      font-weight: 700;
      color: #ffd700;
      letter-spacing: 1px;
      text-shadow: 0 0 10px #ffd700;
    }
    video, canvas {
      border-radius: 15px;
      box-shadow: 0 0 30px #ffd70088;
      margin-top: 20px;
    }
    #status {
      margin-top: 15px;
      font-weight: 500;
      color: #ffd700cc;
      font-size: 1.2rem;
    }
  </style>
</head>
<body>

<header>Age Detection AI</header>
<video id="video" width="320" height="240" autoplay muted></video>
<canvas id="overlay" width="320" height="240"></canvas>
<div id="status">Loading models...</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>

<script>
const video = document.getElementById('video');
const canvas = document.getElementById('overlay');
const status = document.getElementById('status');
const ctx = canvas.getContext('2d');

async function start() {
  await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
  await faceapi.nets.ageGenderNet.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
  status.innerText = "Models loaded. Accessing camera...";

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
    video.srcObject = stream;
  } catch (err) {
    status.innerText = "Camera access denied!";
    console.error(err);
    return;
  }

  video.addEventListener('play', detectFor5Seconds);
}

// Detect continuously for 5 seconds, then stop and return best age
async function detectFor5Seconds() {
  const displaySize = { width: video.width, height: video.height };
  faceapi.matchDimensions(canvas, displaySize);

  let ages = [];
  const startTime = Date.now();

  const interval = setInterval(async () => {
    if (Date.now() - startTime > 5000) { // Stop after 5 seconds
      clearInterval(interval);
      if (ages.length === 0) {
        status.innerText = "No face detected.";
        return;
      }
      // Average age
      const bestAge = Math.round(ages.reduce((a,b) => a+b, 0) / ages.length);
      status.innerText = `Best Age Prediction: ${bestAge}`;
      return;
    }

    const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withAgeAndGender();
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    if (detection) {
      const { x, y, width, height } = detection.detection.box;
      ages.push(detection.age); // Store detected age
      ctx.strokeStyle = '#ffd700';
      ctx.lineWidth = 2;
      ctx.strokeRect(x, y, width, height);
      ctx.fillStyle = '#ffd700';
      ctx.font = '16px Roboto';
      ctx.fillText(`Age: ${Math.round(detection.age)}`, x, y > 20 ? y - 5 : y + 15);
    }
  }, 200); // Every 200ms
}

start();
</script>

</body>
</html>
