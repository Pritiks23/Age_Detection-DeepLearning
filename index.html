<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Age Detection AI</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <style>
    body {
      margin: 0;
      font-family: 'Roboto', sans-serif;
      background: linear-gradient(135deg, #1a1a1a, #3d3d3d);
      color: #fff;
      display: flex;
      flex-direction: column;
      align-items: center;
      min-height: 100vh;
    }
    header {
      padding: 20px;
      text-align: center;
      font-size: 2rem;
      font-weight: 700;
      color: #ffd700;
      letter-spacing: 1px;
      text-shadow: 0 0 10px #ffd700;
    }
    video, canvas {
      border-radius: 15px;
      box-shadow: 0 0 30px #ffd70088;
      margin-top: 20px;
    }
    #status {
      margin-top: 15px;
      font-weight: 500;
      color: #ffd700cc;
      font-size: 1.2rem;
    }
  </style>
</head>
<body>

  <header>Age Detection AI</header>
  <video id="video" width="320" height="240" autoplay muted></video>
  <canvas id="overlay" width="320" height="240"></canvas>
  <div id="status">Loading models...</div>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.13.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlay');
    const status = document.getElementById('status');
    const ctx = canvas.getContext('2d');

    async function start() {
      // Load face detection + age models
      await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
      await faceapi.nets.ageGenderNet.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
      status.innerText = "Models loaded. Accessing camera...";

      // Access webcam
      navigator.mediaDevices.getUserMedia({ video: {} })
        .then(stream => video.srcObject = stream)
        .catch(err => {
          status.innerText = "Camera access denied!";
          console.error(err);
        });

      video.addEventListener('play', detectOnce);
    }

    async function detectOnce() {
      const displaySize = { width: video.width, height: video.height };
      faceapi.matchDimensions(canvas, displaySize);

      // Wait a short moment to allow the video to initialize
      setTimeout(async () => {
        const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withAgeAndGender();
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        if (detection) {
          const { x, y, width, height } = detection.detection.box;
          const age = Math.round(detection.age);
          const gender = detection.gender;

          status.innerText = `Detected Age: ${age}, Gender: ${gender}`;

          // Draw bounding box
          ctx.strokeStyle = '#ffd700';
          ctx.lineWidth = 2;
          ctx.strokeRect(x, y, width, height);
        } else {
          status.innerText = "No face detected.";
        }
      }, 500); // 0.5 sec delay
    }

    start();
  </script>

</body>
</html>

